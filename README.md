# ğŸ“„ Chat with your PDF â€“ A Document-Based Q&A Web App

This application allows you to upload a PDF document and ask questions about its contents using natural language. It utilizes state-of-the-art language models, vector embeddings, and similarity search to return accurate answers with source references.

---

## ğŸš€ Features

- Upload and preview PDF documents
- Ask context-aware questions based on the PDF
- Answers with relevant source excerpts
- Powered by `LLaMA3-8B-8192` via Groq API
- Embedding via `HuggingFace` and search via `FAISS`

---

## ğŸ› ï¸ Setup Instructions

1. **Clone the repository**
   ```bash
   git clone https://github.com/JrMlMaurya/pdf-chat-assistant.git
   cd pdf-chat-assistant
   ```

2. **Create and activate a virtual environment (recommended)**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows use: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Add your Groq API key to a `.env` file**
   Create a file named `.env` in the root directory and add the following line:
   ```
   GROQ_API_KEY=your_groq_api_key_here
   ```
   GROQ_API_KEY - Get it from [HERE](https://groq.com/).

---

## â–¶ï¸ How to Run the App

Simply start the Streamlit app:

```bash
streamlit run app.py
```

Your browser will open a UI where you can upload a PDF and begin querying it.

---

## ğŸ§  How It Works

1. **PDF Upload**:
   - User uploads a PDF.
   - The PDF is rendered in the sidebar for preview.

2. **Document Processing** (`document_loader.py`):
   - Loaded using `PyPDFLoader`.
   - Split into overlapping chunks via `RecursiveCharacterTextSplitter`.
   - Each chunk is embedded using `all-MiniLM-L6-v2`.
   - Vector store is built with `FAISS`.

3. **QA Chain Creation** (`qa_chain.py`):
   - Uses `LLaMA3-8B-8192` model from Groq.
   - Sets up a `RetrievalQA` chain via LangChain.

4. **Interaction** (`app.py`):
   - User inputs a question.
   - The QA chain retrieves relevant document chunks and answers.
   - The answer and supporting content are displayed.

---

## ğŸ“Œ Assumptions

- Only PDF format is supported.
- Each new upload is processed independently (no persistent storage).
- The user provides a valid Groq API key to access the LLM.
- The embeddings model is fixed to `all-MiniLM-L6-v2`.

---

## ğŸ“ File Structure

```
â”œâ”€â”€ app.py                         # Main Streamlit app
â”œâ”€â”€ langchain_backend/
â”‚   â”œâ”€â”€ document_loader.py         # Loads and embeds PDF documents
â”‚   â””â”€â”€ qa_chain.py                # Constructs the QA chain
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ .env                           # Contains the Groq API key (not included)
```

---

## ğŸ“ Contact

For issues or improvements, feel free to open an issue or pull request.

---