{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbf7e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "def process_pdf(file_path: str):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    print(docs)\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    chunks = splitter.split_documents(docs)\n",
    "    print(\"Number of chunks:\", len(chunks))\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Chunk {i}: {chunk.page_content[:100]}...\")  # Print first 100 characters of each chunk\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vectordb = FAISS.from_documents(chunks, embeddings)\n",
    "    return vectordb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d03096a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-05-01T14:06:20+00:00', 'moddate': '2025-05-01T14:06:20+00:00', 'source': 'Take_home_assignment_AdvoraAI.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Take-Home Assignment: PDF Document Query Application \\nWe ask you to complete a take-home assignment to help us evaluate your technical skills and creativity. Your task is to build a simple \\nweb application that allows users to upload PDF documents and query their content via a chat interface, storing up to 5 chat \\nmessages in memory. This aligns with Advora.ai’s focus on AI-driven document processing and knowledge retrieval. \\nAssignment Requirements \\n1. Functionalities: \\n○ PDF Upload: Users can upload a PDF file through the web interface. \\n○ Chat Interface: Users can ask questions about the PDF’s content, and the app responds with relevant answers \\nextracted from the document. \\n○ In-Memory Chat Storage: Store the last 5 chat messages (user questions and AI responses) in memory, displayed in \\nthe chat interface. \\n2. Frontend: \\n○ Build the frontend using Next.js (preferred) or Streamlit if you’re more comfortable with it. \\n○ Include a clean, user-friendly UI with: \\n■ A section for uploading PDFs. \\n■ A chat interface showing the conversation history (up to 5 messages). \\n■ Responsive design for desktop and mobile. \\n3. Backend: \\n○ Process uploaded PDFs to extract text (e.g., using PyPDF2 or pdfplumber in Python). \\n○ Implement a simple text search or RAG-based query system to answer questions based on the PDF content. \\n■ For simplicity, use a keyword-based search or a pre-trained model (e.g., Hugging Face’s sentence-\\ntransformers for embeddings). \\n■ Optional: Integrate a lightweight LLM (e.g., distilbert) for better responses, but this is not required. \\n○ Store the last 5 chat messages in memory (e.g., a list or array in the backend). \\n4. Technical Requirements: \\n○ Use Python for backend logic if using Streamlit or a Python-based Next.js backend (e.g., via API routes). \\n○ For Next.js, use JavaScript/TypeScript for frontend and optionally Python for backend APIs (e.g., FastAPI). \\n○ Ensure the app runs locally with clear setup instructions (e.g., README.md with dependencies and run commands). \\n○ Include basic error handling (e.g., invalid PDF, empty queries). \\n5. Deliverables: \\n○ Source code in a GitHub repository \\n○ A README.md with: \\n■ Setup instructions (e.g., npm install, pip install -r requirements.txt). \\n■ How to run the app (e.g., npm run dev for Next.js, streamlit run app.py for Streamlit). \\n■ A brief explanation of your approach and any assumptions. \\n○ Optional: A short demo video (2-3 minutes) showing the app in action. \\n6. Evaluation Criteria: \\n○ Functionality: Does the app correctly handle PDF uploads and answer queries based on content? \\n○ Chat Storage: Are the last 5 chat messages stored and displayed correctly? \\n○ Code Quality: Is the code clean, modular, and well-documented? \\n○ UI/UX: Is the interface intuitive and responsive? \\n○ Setup: Can the app be easily set up and run based on the provided instructions? \\n○ Creativity: Did you add any thoughtful features (e.g., highlighting relevant PDF sections, chat message timestamps)? \\n7. Time Estimate: 1 - 2 days, depending on familiarity with Next.js or Streamlit. \\n8. Submission: \\n○ Submit your GitHub repository link and any additional materials (e.g., video) to kapila@tepper.cmu.edu with the \\nsubject line “AI Intern Assignment Submission.” \\n○ Deadline: 7 days from receiving this assignment. \\nTips \\n● Chat Storage: Store messages in a simple list (e.g., [{\"user\": \"question\", \"ai\": \"response\"}, ...]) and slice \\nto keep the last 5. \\n● Next.js: Use API routes (/api/upload, /api/query) for backend logic, Vercel for optional deployment, and Tailwind CSS \\nfor styling. \\n● Streamlit: Leverage Streamlit’s file uploader and session state for chat history. \\n● Testing: Test with sample PDFs (e.g., financial reports, legal contracts) to ensure robust text extraction and querying. \\n● Error Handling: Handle cases like corrupt PDFs, empty uploads, or irrelevant queries gracefully.')]\n",
      "Number of chunks: 9\n",
      "Chunk 0: Take-Home Assignment: PDF Document Query Application \n",
      "We ask you to complete a take-home assignment ...\n",
      "Chunk 1: Assignment Requirements \n",
      "1. Functionalities: \n",
      "○ PDF Upload: Users can upload a PDF file through the ...\n",
      "Chunk 2: the chat interface. \n",
      "2. Frontend: \n",
      "○ Build the frontend using Next.js (preferred) or Streamlit if yo...\n",
      "Chunk 3: ○ Implement a simple text search or RAG-based query system to answer questions based on the PDF cont...\n",
      "Chunk 4: 4. Technical Requirements: \n",
      "○ Use Python for backend logic if using Streamlit or a Python-based Next...\n",
      "Chunk 5: ○ Source code in a GitHub repository \n",
      "○ A README.md with: \n",
      "■ Setup instructions (e.g., npm install, ...\n",
      "Chunk 6: ○ Chat Storage: Are the last 5 chat messages stored and displayed correctly? \n",
      "○ Code Quality: Is the...\n",
      "Chunk 7: 8. Submission: \n",
      "○ Submit your GitHub repository link and any additional materials (e.g., video) to k...\n",
      "Chunk 8: for styling. \n",
      "● Streamlit: Leverage Streamlit’s file uploader and session state for chat history. \n",
      "●...\n",
      "Vector database created successfully.\n"
     ]
    }
   ],
   "source": [
    "#run the function with the path to your PDF file\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"Take_home_assignment_AdvoraAI.pdf\"\n",
    "    vectordb = process_pdf(file_path)\n",
    "    print(\"Vector database created successfully.\")\n",
    "    # You can now use vectordb for further processing or querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9a91ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='88095155-b281-4d0d-bbd9-61c8f213def2', metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-05-01T14:06:20+00:00', 'moddate': '2025-05-01T14:06:20+00:00', 'source': 'Take_home_assignment_AdvoraAI.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Take-Home Assignment: PDF Document Query Application \\nWe ask you to complete a take-home assignment to help us evaluate your technical skills and creativity. Your task is to build a simple \\nweb application that allows users to upload PDF documents and query their content via a chat interface, storing up to 5 chat \\nmessages in memory. This aligns with Advora.ai’s focus on AI-driven document processing and knowledge retrieval. \\nAssignment Requirements \\n1. Functionalities:'),\n",
       " Document(id='c9d92568-27c0-4a91-aa91-5c418cb9f0a3', metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-05-01T14:06:20+00:00', 'moddate': '2025-05-01T14:06:20+00:00', 'source': 'Take_home_assignment_AdvoraAI.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Assignment Requirements \\n1. Functionalities: \\n○ PDF Upload: Users can upload a PDF file through the web interface. \\n○ Chat Interface: Users can ask questions about the PDF’s content, and the app responds with relevant answers \\nextracted from the document. \\n○ In-Memory Chat Storage: Store the last 5 chat messages (user questions and AI responses) in memory, displayed in \\nthe chat interface. \\n2. Frontend:'),\n",
       " Document(id='fcc0d464-729f-414e-981e-f09b1a543cc0', metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-05-01T14:06:20+00:00', 'moddate': '2025-05-01T14:06:20+00:00', 'source': 'Take_home_assignment_AdvoraAI.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='for styling. \\n● Streamlit: Leverage Streamlit’s file uploader and session state for chat history. \\n● Testing: Test with sample PDFs (e.g., financial reports, legal contracts) to ensure robust text extraction and querying. \\n● Error Handling: Handle cases like corrupt PDFs, empty uploads, or irrelevant queries gracefully.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.search(\"What is the main topic of the document?\", k=3, search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30285ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "def create_qa_chain(vectorstore):\n",
    "    llm = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")  # Replace with your preferred LLM\n",
    "    chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}),\n",
    "        chain_type=\"stuff\"\n",
    "    )\n",
    "    return chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d040fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"Take_home_assignment_AdvoraAI.pdf\"\n",
    "    vectordb = process_pdf(file_path)\n",
    "    qa_chain = create_qa_chain(vectordb)\n",
    "    \n",
    "    # Example query\n",
    "    query = \"What is the main topic of the document?\"\n",
    "    response = qa_chain.invoke(query)\n",
    "    print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7448630c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'When is the deadline for the assignment?',\n",
       " 'result': 'The deadline for the assignment is 7 days from receiving this assignment.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke(\"When is the deadline for the assignment?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e7d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
